apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-defaults
  namespace: default
  labels:
    app: spark
data:
  spark-defaults.conf: |
    ################################################################################
    # Spark 4.0.1 Defaults (Merged with Legacy & User Requests)
    ################################################################################

    # --- Core Spark Config ---
    spark.master                                k8s://https://kubernetes.default.svc.cluster.local:443
    spark.serializer                            org.apache.spark.serializer.KryoSerializer
    spark.sql.extensions                        io.delta.sql.DeltaSparkSessionExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

    # --- Dynamic Allocation & Graceful Decommission (RESTORED) ---
    # Starts with 1 executor and scales up to 4 based on workload.
    spark.dynamicAllocation.enabled             true
    spark.dynamicAllocation.shuffleTracking.enabled true
    spark.dynamicAllocation.minExecutors        1
    spark.dynamicAllocation.maxExecutors        4
    spark.dynamicAllocation.executorIdleTimeout 600s
    spark.dynamicAllocation.schedulerBacklogTimeout 5s

    # Graceful Decommission (finish tasks before shutdown)
    spark.decommission.enabled                  true
    spark.storage.decommission.enabled          true
    spark.storage.decommission.shuffleBlocks.enabled true
    spark.storage.decommission.rddBlocks.enabled true

    # --- Resources (Legacy Preserved) ---
    spark.executor.cores                        1
    spark.executor.memory                       1g
    spark.driver.cores                          1
    spark.driver.memory                         2g
    spark.driver.memory                         2g
    spark.jars.packages                         io.unitycatalog:unitycatalog-spark_2.13:0.3.1,io.delta:delta-spark_2.13:4.0.0,org.apache.iceberg:iceberg-spark-runtime-3.5_2.13:1.7.0

    # --- Unity Catalog (Native Writer -- Fixed) ---
    spark.sql.catalog.unity                     io.unitycatalog.spark.UCSingleCatalog
    spark.sql.catalog.unity.uri                 http://unity-catalog-unitycatalog-server:8085
    spark.sql.catalog.unity.token               not-used-in-oss-mode

    # Force S3A Scheme (Fixes Protocol Mismatch)
    spark.sql.catalog.unity.warehouse           s3a://warehouse/
    spark.sql.catalog.unity.s3.endpoint         http://minio.default.svc.cluster.local:9000

    # --- UniForm (Delta -> Iceberg Metadata) ---
    spark.databricks.delta.universalFormat.enabledFormats iceberg
    spark.databricks.delta.icebergCompatV2.enabled        true

    # --- MinIO S3A Configuration ---
    spark.hadoop.fs.s3a.endpoint                http://minio.default.svc.cluster.local:9000
    spark.hadoop.fs.s3a.access.key              minioadmin
    spark.hadoop.fs.s3a.secret.key              minioadmin
    spark.hadoop.fs.s3a.path.style.access       true
    spark.hadoop.fs.s3a.connection.ssl.enabled  false
    spark.hadoop.fs.s3a.impl                    org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3.impl                     org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    spark.hadoop.fs.s3a.fast.upload             true

    # --- Delta Lake / UniForm w/ Iceberg ---
    spark.sql.catalog.spark_catalog             org.apache.spark.sql.delta.catalog.DeltaCatalog
    spark.databricks.delta.universalFormat.enabledFormats iceberg
    spark.databricks.delta.icebergCompatV2.enabled true
    # Allow unknown features (like delta.feature.catalogManaged) for UC OSS interop
    spark.databricks.delta.allowArbitraryProperties.enabled true

    # --- RocksDB State Store (RESTORED) ---
    spark.sql.streaming.stateStore.providerClass   org.apache.spark.sql.execution.streaming.state.RocksDBStateStoreProvider
    spark.sql.streaming.stateStore.rocksdb.changelogCheckpointing.enabled true

    # --- Prometheus Monitoring (RESTORED) ---
    spark.ui.prometheus.enabled                 true
    spark.metrics.namespace                     spark
    spark.servicemonitor.port                   4040
    spark.metrics.conf.*.sink.prometheusServlet.class org.apache.spark.metrics.sink.PrometheusServlet
    spark.metrics.conf.*.sink.prometheusServlet.path /metrics/prometheus
    spark.kubernetes.driver.annotation.prometheus.io/scrape true
    spark.kubernetes.driver.annotation.prometheus.io/path   /metrics/prometheus
    spark.kubernetes.driver.annotation.prometheus.io/port   4040
    spark.kubernetes.executor.annotation.prometheus.io/scrape true
    spark.kubernetes.executor.annotation.prometheus.io/path   /metrics/prometheus
    spark.kubernetes.executor.annotation.prometheus.io/port   4040

    # --- Kubernetes Pod Defaults ---
    spark.kubernetes.container.image.pullPolicy Always
    spark.kubernetes.driver.pod.name            spark-driver
    spark.kubernetes.namespace                  default
    spark.kubernetes.executor.podNamePrefix     spark-executor
